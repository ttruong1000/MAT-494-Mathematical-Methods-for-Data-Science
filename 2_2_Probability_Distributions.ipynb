{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO35gV5T4xBGtILMX30Ok0E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttruong1000/MAT-494-Mathematical-Methods-for-Data-Science/blob/main/2_2_Probability_Distributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.2 - Probability Distributions**"
      ],
      "metadata": {
        "id": "QbK52tMOvlI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2.0 - Python Libraries for Probability Distributions**"
      ],
      "metadata": {
        "id": "xn0SNxKI8vLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "YcsCBueL81Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2.1 - Axioms of Probability**"
      ],
      "metadata": {
        "id": "n-GiZohLwC3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.1.1 - Sample Space"
      ],
      "metadata": {
        "id": "1GfhcB479B-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sample space of an experiment, denoted by $S$, is the set of all possible outcomes of that experiment."
      ],
      "metadata": {
        "id": "OTXB88FC9Cwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.1.2 - Events, Simple and Compound"
      ],
      "metadata": {
        "id": "GX0_ph1i9SJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An event is any collection (subset) of outcomes contained in the sample space $S$. An event is simple if it consists of exactly one outocme and compound if it consists of more than one outcome."
      ],
      "metadata": {
        "id": "txJKq_Bv9VVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.1.3 - Probability Distribution"
      ],
      "metadata": {
        "id": "DS-pHpWv9Sb4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given an experiment and a sample space $S$, the probability distribution is a function which assigns to each event $A$ a number $P(A)$, the probability of event $A$, which gives a precise measure of the chance that $A$ will occur. Alternatively, a probability distribution is the mathematical function that gives the probabilities of the occurrences of different possible outcomes for an experiment."
      ],
      "metadata": {
        "id": "snNAPCwV9rXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.1.4 - Axioms of Probability"
      ],
      "metadata": {
        "id": "SsIiTsIF9rox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probability follows the following axioms:\n",
        "- For any event $A$, $0 \\leq P(A) \\leq 1$.\n",
        "- $P(S) = 1$, where $S$ is the sample space.\n",
        "- If $A_1, A_2, A_3, \\ldots$ is an infinite collection of disjoint events, then\n",
        "\\begin{equation*}\n",
        "  P(A_1 \\cup A_2 \\cup A_3 \\cup \\cdots) = \\sum_{i = 1}^\\infty P(A_i)\n",
        "\\end{equation*}\n",
        "- For any event $A$, $P(A) + P(A') = 1$, from which $P(A) = 1 - P(A')$, where $A'$ is the complement of $A$.\n",
        "- When events $A$ and $B$ are mutually exclusive, $P(A \\cup B) = P(A) + P(B)$.\n",
        "- (Principle of Inclusion-Exclusion) For any two events $A$ and $B$,\n",
        "\\begin{equation*}\n",
        "  P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "tu0AlljC9sEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.1.5 - Equally Likely Outcomes"
      ],
      "metadata": {
        "id": "7CHl47aF_ZaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If there are $n$ equally likely outcomes, the probability for each event is $\\frac{1}{n}$. Consider an event $A$, with $N(A)$ denoting the number of outcomes contained in $A$. Then,\n",
        "\\begin{equation*}\n",
        "  P(A) = \\frac{N(A)}{N}\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "Yra9YEB3_Zp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2.2 - Conditional Probability**"
      ],
      "metadata": {
        "id": "mddUC3xYwDHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.2.1 - Conditional Probability"
      ],
      "metadata": {
        "id": "ffS6MbdMAU8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any two events $A$ and $B$ with $P(B) > 0$, the conditional probability of $A$ given that $B$ has occurred is defined by\n",
        "\\begin{equation*}\n",
        "  P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "EKeK3yE9AVOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.2.2 - Independence and Dependence for Two Events"
      ],
      "metadata": {
        "id": "cpP0MypqBQEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two events $A$ and $B$ are independent if $P(A|B) = P(A)$ or $P(A \\cap B) = P(A)P(B)$. If this is otherwise, two events $A$ and $B$ are dependent."
      ],
      "metadata": {
        "id": "g6BA2ogwBUdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.2.3 - Independence for $n$ Events"
      ],
      "metadata": {
        "id": "Uf6dZ0Q8BoiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Events $A_1, A_2, \\ldots, A_n$ are mutually independent if for every $k = 2, 3, \\ldots, n$ and every subset of indices $i_1, i_2, \\ldots, i_k$,\n",
        "\\begin{equation*}\n",
        "  P(A_{i_1} \\cap A_{i_2} \\cap \\cdots \\cap A_{i_k}) = P(A_{i_1})P(A_{i_2}) \\cdots P(A_{i_k})\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "UvU3ZlcUBuvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2.3 - Discrete Random Variables**"
      ],
      "metadata": {
        "id": "qB7iR3mDwDTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.1 - Random Variables"
      ],
      "metadata": {
        "id": "8UWPJNd6Ei7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a given sample space $S$ of some experiment, a random variable is any rule that associates a number with each outcome in $S$. Mathematically, a random variable is a function whose domain is the sample space and whose range is the set of real numbers."
      ],
      "metadata": {
        "id": "Vij7l4sDGlfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.2 - Discrete Random Variables"
      ],
      "metadata": {
        "id": "e6ANQUQAEjRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A discrete random variable is a random variable whose possible values either constitute a finite set or else can be listed in an infinite sequence. A random variable is continuous if both of the following apply.\n",
        "- Its set of possible values consists of all numbers in a single interval on the number line.\n",
        "- $P(X = c) = 0$ for any possible value of $c$."
      ],
      "metadata": {
        "id": "UhvxS9eEICoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.3 - Probability Mass Function (PMF)"
      ],
      "metadata": {
        "id": "SUu5wb_QG3vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The probability distribution or probability mass function (pmf) of a discrete random variable is defined for every number $x$ by\n",
        "\\begin{equation*}\n",
        "  p(x) = P(X = x) = P(\\text{\\{all $s \\in S$ | $X(s) = X$}\\})\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "ChGdvRjSG39z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.4 - Cumulative Distribution Function (CDF)"
      ],
      "metadata": {
        "id": "cv6g8FsYIu6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cumulative distribution function (CDF) $F(x)$ of a discrete random variable $X$ with PMF $p(x)$ is defined for every number $x$ by\n",
        "\\begin{equation*}\n",
        "  F(x) = P(X \\leq x) = \\sum_{y| y \\leq x}p(y)\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "ibbrIYEVIvS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.5 - Bernoulli Random Variables, CDF, PDF"
      ],
      "metadata": {
        "id": "H0sRwbuOKB2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any random variables whose only possible values are 0 and 1 are called Bernoulli random variables. Given Bernoulli experiments with outcomes S (success) and F (failure). The binomial random variable $X$ associated with independent Bernoulli experiment consisting of $n$ trials is defined as\n",
        "\\begin{equation*}\n",
        "  X = \\text{ the number of $S$'s among the $n$ trials}\n",
        "\\end{equation*}\n",
        "The probability of success is $p$ from trial to trial. The PMF of $X$ has the form\n",
        "\\begin{equation*}\n",
        "  b(x; n, p) = \\begin{cases}\n",
        "    \\binom{n}{x}p^x(1-p)^{n - x} &\\text{ $x = 0, 1, 2, 3, \\ldots, n$} \\\\\n",
        "    0 &\\text{ otherwise}\n",
        "  \\end{cases}\n",
        "\\end{equation*}\n",
        "and the CDF of $X$ has the form\n",
        "\\begin{equation*}\n",
        "  B(x; n, p) = P(X \\leq x) = \\sum_{y|y \\leq x}b(x; n, p) = \\sum_{y = 0}^x \\binom{n}{y}p^x(1 - p)^{n - x}\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "_GAbOv7LKCGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.6 - Poisson Distribution, PDF, CDF"
      ],
      "metadata": {
        "id": "rOv0CdsCKC5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Poisson distribution is a discrete probability distribution that describes the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event. A discrete random variable $X$ is said to have a Poisson distribution with parameter $\\mu$ is the PMF of $X$ is\n",
        "\\begin{equation*}\n",
        "  p(x;\\mu) = \\frac{e^{-\\mu}\\mu^x}{x!} \\quad x = 0, 1, 2, 3, \\ldots\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "Ko1DA6bpKDE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.7 - Expected Value of Discrete Random Variables $X$"
      ],
      "metadata": {
        "id": "9D2jjcZHKEf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $X$ be a discrete random variables with set of possible values $D$ and PMF $p(x)$. The expected value or mean value of $X$, denoted by $E(X)$, $\\mu_X$, or $\\mu$, is\n",
        "\\begin{equation*}\n",
        "  E(X) = \\mu_X = \\mu = \\sum_{x \\in D}xp(x)\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "teLJWsAzKEvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proposition 2.2.3.8 - Linearity of Expectation"
      ],
      "metadata": {
        "id": "JOuFYm1wKFCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the random variable $X$ has a set of possible values $D$ and PMF $p(x)$, then the expected value of any function $h(X)$, denoted by $E[h(X)]$ or $\\mu_{h(X)}$, is computed by\n",
        "\\begin{equation*}\n",
        "  E[h(X)] = \\sum_D h(x)p(x)\n",
        "\\end{equation*}\n",
        "In particular,\n",
        "\\begin{equation*}\n",
        "  E(aX+  b) = aE(x) + b\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "OpKBX5WqKFSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M3V-a6GdOD57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.3.9 - Variance and Standard Deviation of Discrete Random Variables"
      ],
      "metadata": {
        "id": "Z4a9uE1JOEQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $X$ have a PMF $p(x)$ and expected value $\\mu$. Then, the variance of $X$, denoted by $V(X)$, $\\sigma^2_X$, or $\\sigma^2$, is\n",
        "\\begin{equation*}\n",
        "  V(X) = \\sum_D (x - \\mu)^2p(x) = E[(X - \\mu)^2]\n",
        "\\end{equation*}\n",
        "The standard deviation (SD) of $X$ is\n",
        "\\begin{equation*}\n",
        "  \\sigma_X = \\sqrt{\\sigma^2_X}\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "JAfxgAnVOr7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Proposition 2.2.3.10 - Properties of Variance and Standard Deviation"
      ],
      "metadata": {
        "id": "lxfub1BfPGm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected value and variance of discrete random variables have the following properties.\n",
        "\\begin{equation*}\n",
        "  V(aX+  b) = \\sigma^2_{aX + b} = a^2\\sigma^2_X \\quad \\text{ and } \\quad \\sigma_{aX + b} = |a|\\sigma_X\n",
        "\\end{equation*}\n",
        "In particular,\n",
        "\\begin{equation*}\n",
        "  \\sigma_{aX} = |a|\\sigma_X \\quad \\sigma_{X + b} = \\sigma_X\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "XIkDrzjZPHMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Proposition 2.2.3.11 - Properties of Variance and Standard Deviation for Binomial and Poisson Distributions"
      ],
      "metadata": {
        "id": "Ig34kcwFPIyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If $X$ is a binomial random variable with parameters $n, p$, then $E(X) = np$, $V(X) = np(1 - p)$, and $\\sigma = \\sqrt{np(1 - p)}$.\n",
        "- If $X$ is a Poisson random variable with parameters $\\mu$, then $E(X) = \\mu$, $V(X) = \\mu$, and $\\sigma = \\sqrt{\\mu}$."
      ],
      "metadata": {
        "id": "OJrxRZmvPJDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2.4 - Continuous Random Variables**"
      ],
      "metadata": {
        "id": "oFUIbQ1DwDjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.4.1 - Continuous Random Variables"
      ],
      "metadata": {
        "id": "4z-ALUjWFmDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $X$ be a continuous random variable. Then, a probability distribution or probability density function (PDF) of $X$ is a function $f(x)$ such that for any two numbers $a$ and $b$ with $a \\leq b$,\n",
        "\\begin{equation*}\n",
        "  P(a \\leq X \\leq b) = \\int_a^b f(x) \\ dx\n",
        "\\end{equation*}\n",
        "The probability that $X$ takes on a value in the interval $[a, b]$ is the area above this interval and under the graph of the density function $f(x)$. This function $f(x)$ must satisfy the following two conditions.\n",
        "- $f(x) \\geq 0$ for all $x$\n",
        "- $\\int_{-\\infty}^{\\infty} f(x) \\ dx = \\text{ the total area under the entire graph of $f(x)$}$"
      ],
      "metadata": {
        "id": "H1t7pwwOFmaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.4.2 - Expected Value of Continuous Random Variables"
      ],
      "metadata": {
        "id": "gSUNzv-dQcVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected or mean value of a continuous random variable $X$ with PDF $f(x)$ is\n",
        "\\begin{equation*}\n",
        "  E(X) = \\mu_X = \\mu = \\int_{-\\infty}^{\\infty} xf(x) \\ dx\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "5YW3jd38QcmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.4.3 - Variance and Standard Deviation of Continuous Random Variables"
      ],
      "metadata": {
        "id": "953EN303UHpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variance of a continuous random variable $X$ with PDF $f(x)$ and the variance is $\\mu$ is\n",
        "\\begin{equation*}\n",
        "  V(X) = \\sigma^2_X = \\sigma^2 = \\int_{-\\infty}^{\\infty} (x - \\mu)^2 f(x) \\ dx = E[(X - \\mu)^2]\n",
        "\\end{equation*}\n",
        "The standard deviation (SD) of $X$ of $\\sigma_X = \\sqrt{V(X)}$."
      ],
      "metadata": {
        "id": "INBVCGWWUH77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Proposition 2.2.4.4 - Properties of Expected Value, Variance, and Standard Deviation of Continuous Random Variables"
      ],
      "metadata": {
        "id": "33GQPVWsUNhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected value and variance of continuous random variables have the following properties.\n",
        "- If $X$ is a continuous random variable with PDF $f(x)$ and the variance is $\\mu$ is\n",
        "\\begin{equation*}\n",
        "  E[h(X)] = \\mu_{h(X)} = \\int_{-\\infty}^{\\infty} h(x)f(x) \\ dx\n",
        "\\end{equation*}\n",
        "- $V(X) = E(X^2) - [E(X)]^2$"
      ],
      "metadata": {
        "id": "1v4FNq5FUNx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.4.5 - Exponential Distribution, PDF, CDF, Expected Value, Variance, Standard Deviation"
      ],
      "metadata": {
        "id": "uZ4ooBSwUXHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuous random variable $X$ has an exponential distribution with parameter $\\lambda > 0$ if the PDF of $X$ is\n",
        "\\begin{equation*}\n",
        "  f(x; \\lambda) = \\begin{cases}\n",
        "    \\lambda e^{-\\lambda x} &\\text{ $x \\geq 0$} \\\\\n",
        "    0 &\\text{ otherwise}\n",
        "  \\end{cases}\n",
        "\\end{equation*}\n",
        "The expected value of an exponential random variable $X$ is found by doing the integral\n",
        "\\begin{equation*}\n",
        "  E(X) = \\int_0^\\infty x\\lambda e^{-\\lambda x} \\ dx\n",
        "\\end{equation*}\n",
        "in which\n",
        "\\begin{equation*}\n",
        "  \\mu = \\sigma = \\frac{1}{\\lambda} \\quad \\sigma^2 = \\frac{1}{\\lambda^2}\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "H-9Bbt7NUX_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.4.6 - Normal Distribution"
      ],
      "metadata": {
        "id": "4nsuB5XLUbkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuous random variable $X$ has a normal distribution with parameters $\\mu$ and $\\sigma$ (or $\\sigma^2$), where $-\\infty < \\mu < \\infty$ and $\\sigma > 0$, if the PDF of $X$ is\n",
        "\\begin{equation*}\n",
        "  f(x;\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
        "\\end{equation*}\n",
        "The computation of $P(a \\leq X \\leq b)$ when $X$ is a normal random variable with parameters $\\mu$ and $\\sigma$ requires evaluating\n",
        "\\begin{equation*}\n",
        "  P(a \\leq X \\leq b) = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\ dx\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "PFM54lqGUby-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 2.2.4.7 - Standard Normal Distribution"
      ],
      "metadata": {
        "id": "aJdBucB7UlR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The normal distribution with parameter values $\\mu = 0$ and $\\sigma = 1$ is called the standard normal distribution. A random variable having a standard normal distribution is called a standard normal random variable and will be denoted by $Z$. The PDF of $Z$ is\n",
        "\\begin{equation*}\n",
        "  f(z;0, 1) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}} \\quad -\\infty < z < \\infty\n",
        "\\end{equation*}\n",
        "The graph of $f(z;0, 1)$ is called the standard normal (or $z$) curve. Its inflection points occur at $z = -1$ and $z = 1$. The CDF of $Z$ is $P(Z \\leq z) = \\int_{-\\infty}^z f(y;0,1) \\ dy$, which we will denote by $\\Phi(z)$."
      ],
      "metadata": {
        "id": "zOwTvAY7Uo-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proposition 2.2.4.8 - Z-Score"
      ],
      "metadata": {
        "id": "3WoREBLAX-6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $X$ has a normal distribution with mean $\\mu$ and standard deviation $\\sigma$, then the Z-score\n",
        "\\begin{equation*}\n",
        "  Z = \\frac{X - \\mu}{\\sigma}\n",
        "\\end{equation*}\n",
        "has a standard normal distrbution. Thus,\n",
        "\\begin{equation*}\n",
        "  P(a \\leq X \\leq b) = P\\left(\\frac{a - \\mu}{\\sigma} \\leq Z \\leq \\frac{b - \\mu}{\\sigma}\\right) = \\Phi\\left(\\frac{b - \\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)\n",
        "\\end{equation*}\n",
        "\\begin{equation*}\n",
        "  P(X \\leq a) = \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right) \\quad P(X \\geq b) = 1 - \\Phi\\left(\\frac{b - \\mu}{\\sigma}\\right)\n",
        "\\end{equation*}\n"
      ],
      "metadata": {
        "id": "3Fwa6LHDYDlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2.5 - References**"
      ],
      "metadata": {
        "id": "VLedJZESwDyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. MAT 494 Chapter 2 Lecture Notes"
      ],
      "metadata": {
        "id": "g-8c5o6lFo2V"
      }
    }
  ]
}