{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb//HLL9dqbHRhJVQCIG+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttruong1000/MAT-494-Mathematical-Methods-for-Data-Science/blob/main/1_4_Principal_Component_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.4 - Principal Component Analysis**"
      ],
      "metadata": {
        "id": "ofL7xM_jcgTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4.0 - Python Libraries for Principal Component Analysis**"
      ],
      "metadata": {
        "id": "PzxOlVZvcltf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python libraries used in linear algebra for computational purposes are NumPy and SciPy."
      ],
      "metadata": {
        "id": "T4j1X6hbmjV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sympy as sp"
      ],
      "metadata": {
        "id": "zulUcHqjmjrv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4.1 - Singular Value Decomposition**"
      ],
      "metadata": {
        "id": "VZg7IEoLmoPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Theorem 1.4.1.1 - The Singular Value Decomposition (SVD) Theorem"
      ],
      "metadata": {
        "id": "3C0dVsZHnAEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $A$ is an $m \\times n$ matrix, then $A$ has a singular value decomposition."
      ],
      "metadata": {
        "id": "ahFtSuWRnDuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Theorem 1.4.1.2 - Dimension of Matrices in SVD"
      ],
      "metadata": {
        "id": "C9TC_CKxnSz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If an $m \\times n$ matrix $A$ has $R$ nonzero singular values $\\sigma_1, \\sigma_2, \\ldots, \\sigma_r \\geq 0$ with $\\sigma_{r + 1}, \\sigma_{r + 2}, \\ldots, \\sigma_n = 0$, then the dimension of the column space of $A$ $\\text{col}(A) = r$."
      ],
      "metadata": {
        "id": "e8cprog8nTEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theorem 1.4.1.3 - The Singular Value Decomposition (SVD)"
      ],
      "metadata": {
        "id": "ZT7LCGBEpRfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $A$ be an $m \\times n$ matrix with the dimension of $\\text{col}(A) = r$. THen, there exists an $m \\times n$ matrix $\\sum$, where the diagonal entries in $D$ are the first $r$ singular values of $A$ with $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r \\geq 0$, and there exists an $m \\times m$ orthogonal matrix $U$ and an $n \\times n$ orthogonal matrix $V$ such that\n",
        "\\begin{equation*}\n",
        "  A = U\\sum V^T\n",
        "\\end{equation*}\n",
        "Any factorization $A = U\\sum V^T$ with $U, V$ orthogonal and $\\sum$ is called a singular value decomposition SVD of $A$. The matrices $U, V$ are not unique, but the diagonal entries of $\\sum$ are unique and are necessarily the singular values of $A$. The columns of $U$ are called left singular vectors of $A$ and the columns of $V$ are called the right singular vectors of $A$."
      ],
      "metadata": {
        "id": "GLQGXEuVpYfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemma 1.4.1.4 - Observations of Matrices in SVD"
      ],
      "metadata": {
        "id": "6Izs0jT9pY1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $A$ be an $m \\times n$ matrix with a singular value decomposition $U\\sum V^T$.\n",
        "- The singular values $\\sigma_1, \\sigma_2, \\ldots, \\sigma_n$ of $A$ are unique; however, the matrices $U$ and $V$ are not unique.\n",
        "- Since $V$ diagonalizes $A^TA$, it follows that the $\\mathbf{v}_j$'s are eigenvectors of $A^TA$.\n",
        "- Since $AA^T = U\\sum\\sum^TU^T$, it follows that $U$ diagonalizes $AA^T$ and that the $\\mathbf{u}_j$'s are eigenvectors of $AA^T$.\n",
        "- Comparing the $j$-th columns of each side of the euqation\n",
        "\\begin{equation*}\n",
        "  AV = U\\sum\n",
        "\\end{equation*}\n",
        "we get\n",
        "\\begin{equation*}\n",
        "  A\\mathbf{v}_j = \\sigma_j\\mathbf{u}_j \\quad j = 1, 2, \\ldots, n\n",
        "\\end{equation*}\n",
        "Similarly,\n",
        "\\begin{equation*}\n",
        "  A^TU = V\\left(\\sum\\right)^T\n",
        "\\end{equation*}\n",
        "and hence\n",
        "\\begin{equation*}\n",
        "  A\\mathbf{u}_j = \\sigma_j\\mathbf{v}_j \\quad j = 1, 2, \\ldots, n\n",
        "\\end{equation*}\n",
        "\\begin{equation*}\n",
        "  A\\mathbf{u}_j = 0 \\quad \\text{ for } j = n + 1, n + 2, \\ldots, m\n",
        "\\end{equation*}\n",
        "The $\\mathbf{v}_j$'s are called the right singular vectors of $A$, and the $\\mathbf{u}_j$'s are called the left singular vectors of $A$.\n",
        "- If $A$ has rank $r$, then\n",
        "  - $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_r$ form an orthonormal basis for the row space of $A^T$ $R(A^T)$.\n",
        "  - $\\mathbf{v}_{r + 1}, \\mathbf{v}_{r + 2}2, \\ldots, \\mathbf{v}_n$ form an orthonormal basis for the null space of $A$ $N(A)$.\n",
        "  - $\\mathbf{u}_1, \\mathbf{u}_2, \\ldots, \\mathbf{u}_r$ form an orthonormal basis for the row space of $A$ $R(A)$.\n",
        "  - $\\mathbf{u}_{r + 1}, \\mathbf{u}_{r + 2}, \\ldots, \\mathbf{u}_n$ form an orthonormal basis for the null space of $A^T$ $N(A^T)$.\n",
        "- The rank of the matrix $A$ is equal to the number of its nonzero signular values,w here singular values are counted according to multiplicity.\n",
        "- In the case that $A$ has rank $r < n$, if we set\n",
        "\\begin{equation*}\n",
        "  U_1 = (\\mathbf{u}_1, \\mathbf{u}_2, \\ldots, \\mathbf{u}_r) \\quad V_1 = (\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_r)\n",
        "\\end{equation*}\n",
        "and define $\\sum_1$ as an $r \\times r$ matrix with nonzero diagonal entries $\\sigma_1, \\sigma_2, \\ldots, \\sigma_r$. Then, $A = U_1\\sum_1V_1^T$, which is the compact form of the singular value decomposition of $A$."
      ],
      "metadata": {
        "id": "VIxKhMTxpc99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Example 1')\n",
        "A = [[1, 1],[1, 1],[0, 0]]\n",
        "U, Sigma, V = np.linalg.svd(A)\n",
        "print('U =\\n', U)\n",
        "print('Sigma =\\n', Sigma)\n",
        "print('V =\\n', V)\n",
        "print('\\nExample 2')\n",
        "A = [[1, 1],[2, 2]]\n",
        "U, Sigma, V = np.linalg.svd(A)\n",
        "print('U =\\n', U)\n",
        "print('Sigma =\\n', Sigma)\n",
        "print('V =\\n', V)\n",
        "print('\\nExample 3')\n",
        "A = [[2, -2],[1, 2]]\n",
        "U, Sigma, V = np.linalg.svd(A)\n",
        "print('U =\\n', U)\n",
        "print('Sigma =\\n', Sigma)\n",
        "print('V =\\n', V)\n",
        "print('\\nExample 4')\n",
        "A = [[1, 3],[3, 1],[0, 0],[0, 0]]\n",
        "U, Sigma, V = np.linalg.svd(A)\n",
        "print('U =\\n', U)\n",
        "print('Sigma =\\n', Sigma)\n",
        "print('V =\\n', V)\n",
        "print('\\nExample 5')\n",
        "A = [[2, 0, 0],[0, 2, 1],[0, 1, 2],[0, 0, 0]]\n",
        "U, Sigma, V = np.linalg.svd(A)\n",
        "print('U =\\n', U)\n",
        "print('Sigma =\\n', Sigma)\n",
        "print('V =\\n', V)\n",
        "print('\\nExample 6')\n",
        "A = [[-2, 8, 20],[14, 19, 10],[2, -2, 1]]\n",
        "U, Sigma, V = np.linalg.svd(A)\n",
        "print('U =\\n', U)\n",
        "print('Sigma =\\n', Sigma)\n",
        "print('V =\\n', V)\n",
        "print('\\nExample 7')\n",
        "A = [[2, 5, 4],[6, 3, 0],[6, 3, 0],[2, 5, 4]]\n",
        "U, Sigma, V = np.linalg.svd(A)\n",
        "print('U =\\n', U)\n",
        "print('Sigma =\\n', Sigma)\n",
        "print('V =\\n', V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKGivSj5nRlA",
        "outputId": "cbf05937-2adb-4e47-9548-8352a1d2762c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1\n",
            "U =\n",
            " [[-0.70710678 -0.70710678  0.        ]\n",
            " [-0.70710678  0.70710678  0.        ]\n",
            " [ 0.          0.          1.        ]]\n",
            "Sigma =\n",
            " [2. 0.]\n",
            "V =\n",
            " [[-0.70710678 -0.70710678]\n",
            " [-0.70710678  0.70710678]]\n",
            "\n",
            "Example 2\n",
            "U =\n",
            " [[-0.4472136  -0.89442719]\n",
            " [-0.89442719  0.4472136 ]]\n",
            "Sigma =\n",
            " [3.16227766e+00 1.57009246e-16]\n",
            "V =\n",
            " [[-0.70710678 -0.70710678]\n",
            " [-0.70710678  0.70710678]]\n",
            "\n",
            "Example 3\n",
            "U =\n",
            " [[-0.89442719  0.4472136 ]\n",
            " [ 0.4472136   0.89442719]]\n",
            "Sigma =\n",
            " [3. 2.]\n",
            "V =\n",
            " [[-0.4472136   0.89442719]\n",
            " [ 0.89442719  0.4472136 ]]\n",
            "\n",
            "Example 4\n",
            "U =\n",
            " [[-0.70710678 -0.70710678  0.          0.        ]\n",
            " [-0.70710678  0.70710678  0.          0.        ]\n",
            " [ 0.          0.          1.          0.        ]\n",
            " [ 0.          0.          0.          1.        ]]\n",
            "Sigma =\n",
            " [4. 2.]\n",
            "V =\n",
            " [[-0.70710678 -0.70710678]\n",
            " [ 0.70710678 -0.70710678]]\n",
            "\n",
            "Example 5\n",
            "U =\n",
            " [[ 0.          1.          0.          0.        ]\n",
            " [-0.70710678  0.         -0.70710678  0.        ]\n",
            " [-0.70710678  0.          0.70710678  0.        ]\n",
            " [ 0.          0.          0.          1.        ]]\n",
            "Sigma =\n",
            " [3. 2. 1.]\n",
            "V =\n",
            " [[-0.         -0.70710678 -0.70710678]\n",
            " [ 1.          0.          0.        ]\n",
            " [ 0.         -0.70710678  0.70710678]]\n",
            "\n",
            "Example 6\n",
            "U =\n",
            " [[ 6.00000000e-01 -8.00000000e-01  5.55111512e-17]\n",
            " [ 8.00000000e-01  6.00000000e-01  1.38777878e-17]\n",
            " [-5.20417043e-18 -5.55111512e-17  1.00000000e+00]]\n",
            "Sigma =\n",
            " [30. 15.  3.]\n",
            "V =\n",
            " [[ 0.33333333  0.66666667  0.66666667]\n",
            " [ 0.66666667  0.33333333 -0.66666667]\n",
            " [ 0.66666667 -0.66666667  0.33333333]]\n",
            "\n",
            "Example 7\n",
            "U =\n",
            " [[-0.5         0.5         0.69043642 -0.15263533]\n",
            " [-0.5        -0.5         0.15263533  0.69043642]\n",
            " [-0.5        -0.5        -0.15263533 -0.69043642]\n",
            " [-0.5         0.5        -0.69043642  0.15263533]]\n",
            "Sigma =\n",
            " [1.20000000e+01 6.00000000e+00 8.18405499e-16]\n",
            "V =\n",
            " [[-0.66666667 -0.66666667 -0.33333333]\n",
            " [-0.66666667  0.33333333  0.66666667]\n",
            " [ 0.33333333 -0.66666667  0.66666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4.2 - Low-Rank Matrix Approximation**"
      ],
      "metadata": {
        "id": "v1RIIjkhmogy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition 1.4.2.1 - Induced Norm"
      ],
      "metadata": {
        "id": "NBuFBL9ynBjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 2-norm of a matrix $A \\in \\mathbb{R}_{m \\times n}$ is\n",
        "\\begin{equation*}\n",
        "  ||A||_2 = \\max_{\\textbf{0} \\neq \\mathbf{x} \\in \\mathbf{R}^m} \\frac{||A\\mathbf{x}||}{||\\mathbf{x}||} = \\max_{\\mathbf{x} \\neq 0, ||\\mathbf{x}|| = 1} ||A\\mathbf{x}|| = \\max_{\\mathbf{x} \\neq 0, ||\\mathbf{x}|| = 1} \\mathbf{x}^TA^TA\\mathbf{x}\n",
        "\\end{equation*}\n"
      ],
      "metadata": {
        "id": "NuvJmxvYnDG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Theorem 1.4.2.2 - Rank of a SVD Matrix"
      ],
      "metadata": {
        "id": "ah24bvAannV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $A \\in \\mathbb{R}^{m \\times n}$ matrix with SVD\n",
        "\\begin{equation*}\n",
        "  A = \\sum_{j = 1}^r \\sigma_j\\mathbf{u}_j\\mathbf{v}_j^T\n",
        "\\end{equation*}\n",
        "For $k < r$, truncate the sum at the $k$-th term\n",
        "\\begin{equation*}\n",
        "  A_k = \\sum_{j = 1}^k \\sigma_j\\mathbf{u}_j\\mathbf{v}_j^T\n",
        "\\end{equation*}\n",
        "The rank of $A_k$ is $\\text{rank}(A_k) = k$. By construction,\n",
        "- the vectors $\\{\\mathbf{u}_j \\ | \\ j = 1, 2, \\ldots, k\\}$ are orthonormal\n",
        "- since $\\sigma_j > 0$ for $j = 1, 2, \\ldots, k$, and the vectors $\\{\\mathbf{u}_j \\ | \\ j = 1, 2, \\ldots, k\\}$ are orthonormal, $\\{\\mathbf{u}_j \\ | \\ j = 1, 2, \\ldots, k\\}$ spans the column space of $A_k$.\n"
      ],
      "metadata": {
        "id": "JC5Ffz9vnt_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lemma 1.4.2.3 - Matrix Norms and Singular Values"
      ],
      "metadata": {
        "id": "srvpoR9lnnrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $A \\in \\mathbb{R}^{m \\times n}$ be a matrix with SVD\n",
        "\\begin{equation*}\n",
        "  A = \\sum_{j = 1}^r \\sigma_j\\mathbf{u}_j\\mathbf{v}_j^T\n",
        "\\end{equation*}\n",
        "where $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r > 0$ and let $A_k$ be the truncation\n",
        "\\begin{equation*}\n",
        "  A_k = \\sum_{j = 1}^k \\sigma_j\\mathbf{u}_j\\mathbf{v}_j^T\n",
        "\\end{equation*}\n",
        "Then,\n",
        "\\begin{equation*}\n",
        "  ||A - A_k||_2^2 = \\sigma_{k + 1}^2\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "Qhp4-uEUnoAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Theorem 1.4.2.4 - Eckart-Young-Mirsky Theorem (Low-Pank Approximation in the Induced Norm)"
      ],
      "metadata": {
        "id": "iz25mPAxnoS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $A \\in \\mathbb{R}^{m \\times n}$ be a matrix with SVD\n",
        "\\begin{equation*}\n",
        "  A = \\sum_{j = 1}^r \\sigma_j\\mathbf{u}_j\\mathbf{v}_j^T\n",
        "\\end{equation*}\n",
        "Let $A_k$ be the truncation\n",
        "\\begin{equation*}\n",
        "  A_k = \\sum_{j = 1}^k \\sigma_j\\mathbf{u}_j\\mathbf{v}_j^T\n",
        "\\end{equation*}\n",
        "with $k < r$. Then, for any matrix $B \\in \\mathbb{R}^{m \\times n}$ of rank at most $k$,\n",
        "\\begin{equation*}\n",
        "  ||A - A_k|_2 \\leq ||A - B||_2\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "0FyZdoDJozBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4.3 - Principal Component Analysis**"
      ],
      "metadata": {
        "id": "BE48qvYnmpUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 1.4.3.1 - Sample Mean The Mean-Deviation Matrix"
      ],
      "metadata": {
        "id": "oWn0lOkSV8Pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $[\\mathbf{X}_1, \\mathbf{X}_2, \\ldots, \\mathbf{X}_n]$ be a $p \\times N$ matrix of observation. Then, the sample mean $M$ of the observation vectors $\\mathbf{X}_1, \\mathbf{X}_2, \\ldots, \\mathbf{X}_n$ is\n",
        "\\begin{equation*}\n",
        "  \\mathbf{M} = \\frac{1}{N}(\\mathbf{X}_1 + \\mathbf{X}_2 + \\ldots + \\mathbf{X}_n)\n",
        "\\end{equation*}\n",
        "Let the mean-deviation matrix $B$ be\n",
        "\\begin{equation*}\n",
        "  B = [\\hat{\\mathbf{X}}_1, \\hat{\\mathbf{X}}_2, \\ldots, \\hat{\\mathbf{X}}_n]\n",
        "\\end{equation*}\n",
        "where $\\hat{\\mathbf{X}}_k = \\mathbf{X}_k - \\mathbf{M}$ for all $k = 1, 2, \\ldots, N$. The mean-deviation matrix $B$ has a sample mean of zero."
      ],
      "metadata": {
        "id": "0AJtV_e0nCTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 1.4.3.2 - The Covariance Matrix"
      ],
      "metadata": {
        "id": "Fn5YNRDsnCir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The (sample) covariance matrix is the $p \\times p$ matrix $S$ such that\n",
        "\\begin{equation*}\n",
        "  S = \\frac{1}{N - 1}BB^T\n",
        "\\end{equation*}\n",
        "where $B$ is the $p \\times N$ mean-deviation matrix and $N$ is the number of vectors in $B$."
      ],
      "metadata": {
        "id": "pHqfWpeMWJjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 1.4.3.3 - Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "IqnnuwslWZde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $B$ be the $p \\times N$ mean-deviation matrix. Principal Component Analysis (PCA) is a method that finds the first $k$ orthonormal vectors $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$, where $k \\leq p$, such that the objective function\n",
        "\\begin{equation*}\n",
        "  \\frac{1}{N}\\sum_{i = 1}^N \\sum_{j = 1}^N \\langle \\mathbf{X}_i, \\mathbf{v}_j \\rangle^2\n",
        "\\end{equation*}\n",
        "is maximized, where $\\langle \\mathbf{X}_i, \\mathbf{v}_j \\rangle$ is the length of the projection of $\\mathbf{X}_i$ to $\\mathbf{v}_j$."
      ],
      "metadata": {
        "id": "qUvvu8GDXBT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 1.4.3.4 - Variance and Total Variance"
      ],
      "metadata": {
        "id": "Oyo5PEiqWZyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $B$ be the $p \\times N$ mean-deviation matrix and let $S$ be the covariance matrix. For each $j = 1, 2, \\ldots, N$ in $\\mathbf{X}_j$ of $S$, the diagonal entries of the covariance matrix $S$ are the variances of each $\\mathbf{X}_j$. This variance measures the spread of the values of $\\mathbf{X}_j$. The total variance of the data is the sum of the variances on the diagonal of $S$. Alternatively, the total variance can be written as\n",
        "\\begin{equation*}\n",
        "  \\text{Total Variance} = \\text{tr}(S)\n",
        "\\end{equation*}\n",
        "where $\\text{tr}(S)$ is the trace of matrix $S$, the function that takes the sum of the diagonals of a square matrix $S$."
      ],
      "metadata": {
        "id": "b4oIL0LUYYqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definition 1.4.3.5 - Fraction of Variances in Principal Component Analysis"
      ],
      "metadata": {
        "id": "rdPENHuuZg8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fraction of the variances of the first $k$-term truncation under Principal Component Analysis is\n",
        "\\begin{equation*}\n",
        "  \\frac{\\sum_{j = 1}^k \\lambda_j}{\\sum_{j = 1}^p \\lambda_j}\n",
        "\\end{equation*}\n",
        "where $\\lambda_j$ are the eigenvalues of the singular value decompostion (SVD) of $S$."
      ],
      "metadata": {
        "id": "ITTVLSWvZ2hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4.4 - References**"
      ],
      "metadata": {
        "id": "SvM0iX06nxEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. MAT 494 Chapter 1 Lecture 1 Notes\n",
        "2. Steven J. Leon, Linear Algebra with Applications, 9th Edition"
      ],
      "metadata": {
        "id": "SicLljVlnxVz"
      }
    }
  ]
}